# Smart-Coach
This project aims to support football coaches in making better decisions by automatically analyzing playersâ€™ emotions and physical movements from match videos.  It uses AI models to detect facial emotions and track each playerâ€™s speed, direction, and position over time. Then, it combines both  data to generate  psychological  insights by LLM.
### ğŸ” Built With:
- Python
- OpenCV
- PyTorch
- HuggingFace Transformers
- MTCNN / DeepSort
- ResNet18
- Google Colab

### ğŸ† Built During:
AI League Hackathon by Sky & Tuwaiq Academy

### ğŸ“‚ Files:
- Faces_dataset.zip: A Custom labeled dataset containing facial images of football plyers and corresponding emotion labels used for training.
- model.py: trains A custom emotion classification model (based on pretrained resnet18) on a manually collected dataset of football plyers' facial expressions.
- emotion_model.pth: The trained model.
- vedio_processing.py: Processes video and tracks players to classify their emotions and detect theit physical info, then generate a json report that contains this information.
- Final_report_named.json: Example of a JSON report generated by video processing code.
- LLM_feedback.py: Generates a player psychological feedback using local LLM.

 ## ğŸ“„ License
This project is not licensed for public use. All rights are reserved by the author.  
You may not copy, distribute, or modify this project without explicit permission.
